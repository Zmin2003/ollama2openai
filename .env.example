# ============================================
# Ollama2OpenAI v3.0 Enterprise Configuration
# Copy this file to .env and modify as needed
# ============================================

# ---- Server ----
PORT=3000

# Trust proxy (set true if behind nginx/cloudflare)
# TRUST_PROXY=true

# ---- Authentication ----
# Admin panel password
ADMIN_PASSWORD=admin123

# Legacy API token (single token mode)
# Clients send: Authorization: Bearer <token>
# For multi-token mode, create tokens in admin panel instead
API_TOKEN=

# ---- Ollama Backend ----
# Default Ollama backend URL (can be overridden per-key)
OLLAMA_BASE_URL=https://ollama.com/api

# Connection timeout in ms
CONNECT_TIMEOUT=30000

# Request timeout in ms (non-streaming)
REQUEST_TIMEOUT=300000

# Max retries when a key fails
MAX_RETRIES=2

# Health check interval in seconds (0 to disable)
HEALTH_CHECK_INTERVAL=60

# ---- Rate Limiting ----
# Global rate limit
RATE_LIMIT_GLOBAL_ENABLED=true
RATE_LIMIT_GLOBAL_WINDOW=60000
RATE_LIMIT_GLOBAL_MAX=500

# Per-IP rate limit
RATE_LIMIT_IP_ENABLED=true
RATE_LIMIT_IP_WINDOW=60000
RATE_LIMIT_IP_MAX=60

# Per-token rate limit
RATE_LIMIT_TOKEN_ENABLED=true
RATE_LIMIT_TOKEN_WINDOW=60000
RATE_LIMIT_TOKEN_MAX=120

# ---- IP Access Control ----
# Mode: disabled, whitelist, blacklist
IP_ACCESS_MODE=disabled
# Comma-separated IPs (also manageable via admin panel)
# IP_WHITELIST=192.168.1.0/24,10.0.0.1
# IP_BLACKLIST=

# ---- Logging ----
# Log level: debug, info, warn, error
LOG_LEVEL=info

# Write request logs to file (data/logs/)
LOG_TO_FILE=false

# Max recent logs kept in memory for admin panel
LOG_RECENT_MAX=500

# ---- Cache ----
# Embeddings cache
CACHE_EMBEDDINGS=true
CACHE_EMBEDDINGS_MAX_SIZE=1000
CACHE_EMBEDDINGS_MAX_AGE=3600000

# Chat completions cache (non-streaming only)
CACHE_CHAT=false
CACHE_CHAT_MAX_SIZE=500
CACHE_CHAT_MAX_AGE=1800000  # 30 minutes in ms
