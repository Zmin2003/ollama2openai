# ============================================
# Ollama2OpenAI Configuration
# ============================================

# Server port
PORT=3000

# Admin panel password (CHANGE THIS!)
ADMIN_PASSWORD=admin123

# API access token (optional, leave empty to disable auth)
# Clients use this as Bearer token: Authorization: Bearer <API_TOKEN>
API_TOKEN=

# Default Ollama API base URL (for self-hosted Ollama)
# Can also use https://ollama.com/api for cloud
OLLAMA_BASE_URL=https://ollama.com/api

# Health check interval in seconds (default: 60)
HEALTH_CHECK_INTERVAL=60

# Connect timeout in milliseconds (default: 30000 = 30s)
# Only applies to establishing connection, not to streaming data
CONNECT_TIMEOUT=30000

# Request timeout in milliseconds (default: 300000 = 5 min)
# For non-streaming requests (models list, non-stream completions, embeddings)
REQUEST_TIMEOUT=300000

# Max retries on failure (auto switches to next key, default: 2)
MAX_RETRIES=2

# Log level: debug, info, warn, error
LOG_LEVEL=info

# ============================================
# Cache Configuration
# ============================================

# Embeddings cache (default: enabled)
CACHE_EMBEDDINGS=true
CACHE_EMBEDDINGS_MAX_SIZE=5000
CACHE_EMBEDDINGS_MAX_AGE=86400000  # 24 hours in ms

# Chat completions cache (default: disabled)
# Enable for FAQ/testing scenarios with repeated queries
CACHE_CHAT=false
CACHE_CHAT_MAX_SIZE=1000
CACHE_CHAT_MAX_AGE=3600000  # 1 hour in ms
